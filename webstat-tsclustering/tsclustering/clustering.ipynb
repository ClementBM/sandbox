{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/clem/Documents/source/sandbox/webstat-tsclustering/.venv/lib/python3.8/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import http.client\n",
    "from urllib.parse import urlencode, quote_plus, quote\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tslearn.clustering import TimeSeriesKMeans, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from tslearn.utils import to_time_series_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"final_df.csv\", index_col=0)\n",
    "final_df_wona = final_df.dropna(axis=1)\n",
    "normalized_final_df = (final_df_wona - final_df_wona.mean()) / final_df_wona.std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to `tslearn` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = to_time_series_dataset(normalized_final_df.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 240, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape # n_ts, max_sz, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 0.34938194769965675\n",
      "3: 0.26612659244609793\n",
      "4: 0.25588602064105825\n",
      "5: 0.27682811418614217\n",
      "6: 0.2379344426483915\n"
     ]
    }
   ],
   "source": [
    "for cluster_count in range(2, 7):\n",
    "    km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\", n_jobs=2, n_init=5)\n",
    "    labels = km.fit_predict(X_train)\n",
    "    score = silhouette_score(X_train, labels, metric=\"dtw\", n_jobs=4)\n",
    "    print(f\"{cluster_count}: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_COUNT = 6\n",
    "# km = TimeSeriesKMeans(n_clusters=CLUSTER_COUNT, metric=\"dtw\", n_jobs=2, n_init=5)\n",
    "# labels = km.fit_predict(X_train)\n",
    "\n",
    "plt.figure(figsize=(18,14))\n",
    "\n",
    "for yi in range(CLUSTER_COUNT):\n",
    "    plt.subplot(CLUSTER_COUNT, 1, yi + 1)\n",
    "    for xx in X_train[labels == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=0.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    # plt.xlim(0, 1000)\n",
    "    # plt.ylim(-4, 4)\n",
    "    plt.text(0.55, 0.85, \"Cluster %d\" % (yi + 1), transform=plt.gca().transAxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# { i: column_name for i, column_name in enumerate(normalized_final_df.columns) }\n",
    "# cluster_serie_indices = np.where(labels == i)[0]\n",
    "\n",
    "column_names = np.array(normalized_final_df.columns)\n",
    "\n",
    "cluster_sizes = []\n",
    "names_by_cluster = []\n",
    "series_by_cluster = []\n",
    "\n",
    "for i in range(CLUSTER_COUNT):\n",
    "    cluster_series = X_train[labels == i]\n",
    "    series_by_cluster.append(cluster_series)\n",
    "\n",
    "    cluster_serie_names = column_names[labels == i]\n",
    "    names_by_cluster.append(cluster_serie_names)\n",
    "\n",
    "    cluster_size = len(cluster_series)\n",
    "    cluster_sizes.append(cluster_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_by_cluster[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
