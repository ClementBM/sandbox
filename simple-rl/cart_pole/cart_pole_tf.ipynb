{"cells":[{"cell_type":"code","execution_count":1,"source":["import base64\n","import imageio\n","import IPython\n","import tensorflow as tf"],"outputs":[{"output_type":"stream","name":"stderr","text":["2023-02-01 14:42:51.759388: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-02-01 14:42:51.867587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:}\n","2023-02-01 14:42:51.867605: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","2023-02-01 14:42:52.393898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:}\n","2023-02-01 14:42:52.393984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:}\n","2023-02-01 14:42:52.393991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["def train_agent(agent, dataset, collect_driver, tf_env, n_iterations):\n","    time_step = None\n","    policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)\n","    iterator = iter(dataset)\n","    for iteration in range(n_iterations):\n","        time_step, policy_state = collect_driver.run(time_step, policy_state)\n","        trajectories, buffer_info = next(iterator)\n","        train_loss = agent.train(trajectories)\n","        print(\"\\r{} loss:{:.5f}\".format(iteration, train_loss.loss.numpy()), end=\"\")\n","\n","def embed_mp4(filename):\n","    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n","    video = open(filename, \"rb\").read()\n","    b64 = base64.b64encode(video)\n","    tag = \"\"\"\n","  <video width=\"640\" height=\"480\" controls>\n","    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n","  Your browser does not support the video tag.\n","  </video>\"\"\".format(\n","        b64.decode()\n","    )\n","    return IPython.display.HTML(tag)\n","\n","def create_policy_eval_video(tf_env, env, agent, filename, num_episodes=5, fps=30):\n","    filename = filename + \".mp4\"\n","    with imageio.get_writer(filename, fps=fps) as video:\n","        for _ in range(num_episodes):\n","            time_step = tf_env.reset()\n","            policy_state = agent.collect_policy.get_initial_state(tf_env.batch_size)\n","            action_step = agent.policy.action(time_step, policy_state)\n","            video.append_data(env.render())\n","            while not time_step.is_last():\n","                action_step = agent.policy.action(time_step, action_step.state)\n","                time_step = tf_env.step(action_step.action)\n","                video.append_data(env.render())\n","    return embed_mp4(filename)"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["def train():\n","    env = suite_gym.load(\"CartPole-v0\")\n","    tf_env = tf_py_environment.TFPyEnvironment(env)\n","    # Network\n","    rnn_network = q_rnn_network.QRnnNetwork(\n","        tf_env.observation_spec(), tf_env.action_spec(), lstm_size=(20,)\n","    )\n","    # Agent\n","    update_period = 4  # train the model every 4 steps\n","    train_step = tf.Variable(0)\n","    agent = DqnAgent(\n","        tf_env.time_step_spec(),\n","        tf_env.action_spec(),\n","        q_network=rnn_network,\n","        optimizer=tf.keras.optimizers.Nadam(learning_rate=0.01),\n","        target_update_period=10,\n","        td_errors_loss_fn=tf.keras.losses.Huber(\n","            reduction=\"none\"\n","        ),  # tf.keras.losses.binary_crossentropy\n","        gamma=0.95,  # discount factor\n","        train_step_counter=train_step,\n","        epsilon_greedy=lambda: tf.keras.optimizers.schedules.PolynomialDecay(\n","            initial_learning_rate=1.0, decay_steps=2500, end_learning_rate=0.01\n","        )(train_step),\n","    )\n","    agent.initialize()\n","    # Replay buffer\n","    replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n","        data_spec=agent.collect_data_spec,\n","        batch_size=tf_env.batch_size,\n","        max_length=10000,\n","    )\n","    replay_buffer_observer = replay_buffer.add_batch\n","    # Training metrics\n","    training_metrics = [\n","        tf_metrics.NumberOfEpisodes(),\n","        tf_metrics.EnvironmentSteps(),\n","        tf_metrics.AverageReturnMetric(),\n","        tf_metrics.AverageEpisodeLengthMetric(),\n","    ]\n","    # Collect driver\n","    collect_driver = DynamicStepDriver(\n","        tf_env,\n","        agent.collect_policy,\n","        observers=[replay_buffer_observer] + training_metrics,\n","        num_steps=update_period,  # train the model every 4 steps\n","    )\n","    initial_collect_policy = RandomTFPolicy(\n","        tf_env.time_step_spec(), tf_env.action_spec()\n","    )\n","    initial_driver = DynamicStepDriver(\n","        tf_env,\n","        initial_collect_policy,\n","        observers=[replay_buffer.add_batch],\n","        num_steps=1000,\n","    )\n","    final_time_step, final_policy_state = initial_driver.run()\n","    # The Dataset\n","    dataset = replay_buffer.as_dataset(\n","        sample_batch_size=64, num_steps=2, num_parallel_calls=3\n","    ).prefetch(3)\n","    # Training Loop\n","    collect_driver.run = function(collect_driver.run)\n","    agent.train = function(agent.train)\n","    return agent, dataset, collect_driver, tf_env, env"],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":4,"source":["agent, dataset, collect_driver, tf_env, env = train()\n","train_agent(agent, dataset, collect_driver, tf_env, 10000)\n","create_policy_eval_video(tf_env, env, agent, \"trained-agent\", num_episodes=1)"],"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'suite_gym' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py\u001b[0m in \u001b[0;36mline 1\n\u001b[0;32m----> <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=127'>128</a>\u001b[0m agent, dataset, collect_driver, tf_env, env \u001b[39m=\u001b[39m train()\n\u001b[1;32m      <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=128'>129</a>\u001b[0m train_agent(agent, dataset, collect_driver, tf_env, \u001b[39m10000\u001b[39m)\n\u001b[1;32m      <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=129'>130</a>\u001b[0m create_policy_eval_video(tf_env, env, agent, \u001b[39m\"\u001b[39m\u001b[39mtrained-agent\u001b[39m\u001b[39m\"\u001b[39m, num_episodes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n","\u001b[1;32m/home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py\u001b[0m in \u001b[0;36mline 2\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\n\u001b[1;32m      <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m():\n\u001b[0;32m----> <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=7'>8</a>\u001b[0m     env \u001b[39m=\u001b[39m suite_gym\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39mCartPole-v0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=8'>9</a>\u001b[0m     tf_env \u001b[39m=\u001b[39m tf_py_environment\u001b[39m.\u001b[39mTFPyEnvironment(env)\n\u001b[1;32m      <a href='file:///home/clem/Documents/source/test-bot/bnbot/sandbox/cart_pole_tf.py?line=9'>10</a>\u001b[0m     \u001b[39m# Network\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'suite_gym' is not defined"]}],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":4}}